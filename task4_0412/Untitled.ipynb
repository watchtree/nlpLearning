{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "vectorizer=CountVectorizer()  # 文本特征提取类\n",
    "corpus=[\"I come to China to travel\", \n",
    "    \"This is a car polupar in China\",          \n",
    "    \"I love tea and Apple \",   \n",
    "    \"The work is to write some papers in science\"] \n",
    "vec_fit = vectorizer.fit_transform(corpus) #对于corpus训练样本，生成对应的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'apple', 'car', 'china', 'come', 'in', 'is', 'love', 'papers', 'polupar', 'science', 'some', 'tea', 'the', 'this', 'to', 'travel', 'work', 'write']\n"
     ]
    }
   ],
   "source": [
    "# 获取列表形式文本\n",
    "print(vectorizer.get_feature_names())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'come': 4, 'to': 15, 'china': 3, 'travel': 16, 'this': 14, 'is': 6, 'car': 2, 'polupar': 9, 'in': 5, 'love': 7, 'tea': 12, 'and': 0, 'apple': 1, 'the': 13, 'work': 17, 'write': 18, 'some': 11, 'papers': 8, 'science': 10}\n"
     ]
    }
   ],
   "source": [
    "# 打印字典\n",
    "print(vectorizer.vocabulary_)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 15)\t2\n",
      "  (0, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 7)\t1\n",
      "  (3, 10)\t1\n",
      "  (3, 8)\t1\n",
      "  (3, 11)\t1\n",
      "  (3, 18)\t1\n",
      "  (3, 17)\t1\n",
      "  (3, 13)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 15)\t1\n"
     ]
    }
   ],
   "source": [
    "print(vec_fit)\n",
    "# 第0个列表元素，**词典中索引为3的元素**， 词频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 2 1 0 0]\n",
      " [0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vec_fit.toarray()) #.toarray() 是将结果转化为稀疏矩阵矩阵的表示方式；\n",
    "# 下面是一个字典\n",
    "# 第一句话的 词 分别的位置和出现的字数\n",
    "# 稀疏矩阵表示方式\n",
    "# 第一句话可以用第一个向量表示，不能表示出顺序关系，只能看出存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 3 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#每个词在所有文档中的词频，统计每一词出现的次数\n",
    "print(vec_fit.toarray().sum(axis=0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    " \n",
    "corpus=[\"I come to China to travel\", \n",
    "    \"This is a car polupar in China\",          \n",
    "    \"I love tea and Apple \",   \n",
    "    \"The work is to write some papers in science\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 15)\t2\n",
      "  (0, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 7)\t1\n",
      "  (3, 10)\t1\n",
      "  (3, 8)\t1\n",
      "  (3, 11)\t1\n",
      "  (3, 18)\t1\n",
      "  (3, 17)\t1\n",
      "  (3, 13)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 15)\t1\n"
     ]
    }
   ],
   "source": [
    "# 调用文本向量化 的类\n",
    "vectorizer=CountVectorizer()\n",
    "print(vectorizer.fit_transform(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t0.4424621378947393\n",
      "  (0, 15)\t0.697684463383976\n",
      "  (0, 4)\t0.4424621378947393\n",
      "  (0, 3)\t0.348842231691988\n",
      "  (1, 14)\t0.45338639737285463\n",
      "  (1, 9)\t0.45338639737285463\n",
      "  (1, 6)\t0.3574550433419527\n",
      "  (1, 5)\t0.3574550433419527\n",
      "  (1, 3)\t0.3574550433419527\n",
      "  (1, 2)\t0.45338639737285463\n",
      "  (2, 12)\t0.5\n",
      "  (2, 7)\t0.5\n",
      "  (2, 1)\t0.5\n",
      "  (2, 0)\t0.5\n",
      "  (3, 18)\t0.3565798233381452\n",
      "  (3, 17)\t0.3565798233381452\n",
      "  (3, 15)\t0.2811316284405006\n",
      "  (3, 13)\t0.3565798233381452\n",
      "  (3, 11)\t0.3565798233381452\n",
      "  (3, 10)\t0.3565798233381452\n",
      "  (3, 8)\t0.3565798233381452\n",
      "  (3, 6)\t0.2811316284405006\n",
      "  (3, 5)\t0.2811316284405006\n"
     ]
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus)) \n",
    "# 输出的各个文本各个词的 TF-IDF 值\n",
    "print (tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.34884223 0.44246214 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.69768446 0.44246214 0.\n",
      "  0.        ]\n",
      " [0.         0.         0.4533864  0.35745504 0.         0.35745504\n",
      "  0.35745504 0.         0.         0.4533864  0.         0.\n",
      "  0.         0.         0.4533864  0.         0.         0.\n",
      "  0.        ]\n",
      " [0.5        0.5        0.         0.         0.         0.\n",
      "  0.         0.5        0.         0.         0.         0.\n",
      "  0.5        0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.28113163\n",
      "  0.28113163 0.         0.35657982 0.         0.35657982 0.35657982\n",
      "  0.         0.35657982 0.         0.28113163 0.         0.35657982\n",
      "  0.35657982]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.toarray()) #.toarray() 是将结果转化为稀疏矩阵矩阵的表示方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
